{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354707f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from nltk.corpus import wordnet as wn\n",
    "from torchvision.datasets import CIFAR100, ImageNet\n",
    "from google_images_search import GoogleImagesSearch\n",
    "import PIL\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9aa43a",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "    1. Try to use polysemous words, ideally with one sense more popular than the other\n",
    "    \n",
    "    2. Dataset analysis, underrepresented classes/combination of classes and performance on them\n",
    "    \n",
    "    3. Object detection, answer present/absent\n",
    "    \n",
    "    4. Understand loss(if present) of robustness when fine tuned on datasets as compared to zero shot evaluation\n",
    "    \n",
    "    5. Ability of CLIP to detect actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f217681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "model.cuda().eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95853ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarities(images, texts):\n",
    "    scores = []\n",
    "    for image in images:\n",
    "#         print(type(image))\n",
    "        with torch.no_grad():\n",
    "            image = preprocess(image).unsqueeze(0).to(device)\n",
    "            image_features = model.encode_image(image)\n",
    "            text_features = model.encode_text(texts)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "        scores.append(similarity)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656be18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(dir_path):\n",
    "    dir_path = dir_path.replace(' ', '_')\n",
    "    print(dir_path)\n",
    "    images = []\n",
    "    for file in os.listdir(dir_path):\n",
    "        try:\n",
    "            images.append(Image.open(dir_path+'/'+file, 'r'))\n",
    "        except PIL.UnidentifiedImageError as e:\n",
    "            print(dir_path+'/'+file)\n",
    "        except IsADirectoryError as e:\n",
    "            pass\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e43af61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bee54bbce113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"yellow sun in blue sky\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image_dir' is not defined"
     ]
    }
   ],
   "source": [
    "def blue_to_yellow(a):\n",
    "    a = np.asarray(a, dtype=\"int32\" ).astype(np.float)\n",
    "    new_a = (a[:,:,0]+a[:,:,1], a[:,:,0]-a[:,:,1], a[:,:,2])\n",
    "    new_a = (new_a[2], new_a[1], new_a[0])\n",
    "    #print(np.abs(a[:,:,0] - (new_a[0]+new_a[1])/2).max())\n",
    "    new_a = np.stack( ((new_a[0]+new_a[1])/2, (new_a[0]-new_a[1])/2, new_a[2]), axis=-1)\n",
    "    return Image.fromarray(new_a.astype(np.uint8), \"RGB\" )\n",
    "\n",
    "def invert(image):\n",
    "    return PIL.ImageOps.invert(image)\n",
    "\n",
    "def alter_brightness(image, factor):\n",
    "    enhancer = PIL.ImageEnhance.Brightness(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def rotate(image, angle):\n",
    "    return image.rotate(angle)\n",
    "\n",
    "def add_salt_and_pepper(image, amount):\n",
    "    output = np.copy(np.array(image))\n",
    "    # add pepper\n",
    "    nb_pepper = np.ceil(amount* output.size * 0.5)\n",
    "    coords = [np.random.randint(0, i - 1, int(nb_pepper)) for i in output.shape[:2]]\n",
    "    for i, j in zip(coords[0], coords[1]):\n",
    "        output[i][j] = 0\n",
    "    \n",
    "    # add salt\n",
    "    nb_salt = np.ceil(amount * output.size * 0.5)\n",
    "    coords = [np.random.randint(0, i - 1, int(nb_salt)) for i in output.shape[:2]]\n",
    "    for i, j in zip(coords[0], coords[1]):\n",
    "        output[i][j] = 256\n",
    "#     output[coords] = 1    \n",
    "    return Image.fromarray(output)\n",
    "\n",
    "def add_gaussian_noise(image, sigma):\n",
    "    output = np.copy(np.array(image))\n",
    "    noise = np.random.normal(size=output.shape[:2])*sigma\n",
    "    output += np.stack((noise, noise, noise), axis=-1).astype(np.uint8)\n",
    "    return Image.fromarray(output)\n",
    "\n",
    "def transformation(dir_path, transform):\n",
    "    dir_path = dir_path.replace(' ', '_')\n",
    "    print(dir_path)\n",
    "    images = []\n",
    "    for file in os.listdir(dir_path):\n",
    "        image = Image.open(dir_path+'/'+file, 'r')\n",
    "        image = transform(image)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "images = transformation(image_dir+'/'+\"yellow sun in blue sky\", lambda x: rotate(x, -45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49db77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(queries, text_probes=None):\n",
    "    images = dict([(q, load_images(image_dir+'/'+q)) for q in queries])\n",
    "    if text_probes is None:\n",
    "        text_probes = [\"a photo of an \"+q for q in queries]\n",
    "    text_probes = torch.cat([clip.tokenize(text) for text in text_probes]).to(device)\n",
    "    scores= dict([])\n",
    "    for q, imgs in images.items():\n",
    "        scores[q] = get_similarities(imgs, text_probes) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52da1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = './images_google_search'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc860098",
   "metadata": {},
   "source": [
    "# Polysemous words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083bfbb2",
   "metadata": {},
   "source": [
    "## Apple (fruit vs logo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e33822f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/apple_fruit_cartoon\n",
      "./images_google_search/apple_fruit\n"
     ]
    }
   ],
   "source": [
    "queries = [\"apple fruit cartoon\", \"apple fruit\"]\n",
    "scores = get_scores(queries, text_probes=[\"a drawing of an apple\", \"a photo of an apple\"])\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "760b9a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 10],\n",
       "       [ 4, 40]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d796bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  9],\n",
       "       [ 3, 41]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61909d",
   "metadata": {},
   "source": [
    "Probes tried:\n",
    "\n",
    "    1. [\"a photo of the Apple logo\", \"a photo of an apple fruit\"]\n",
    "        [[50,  0],\n",
    "        [17, 33]]\n",
    "    2. [\"a photo of a tree\", \"a photo of an apple fruit\"] (contrast with tree)\n",
    "        [[50,  0],\n",
    "       [ 0, 50]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7113e",
   "metadata": {},
   "source": [
    "## Tree (Graph vs normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3287b68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/tree\n",
      "./images_google_search/tree_graph\n"
     ]
    }
   ],
   "source": [
    "queries = [\"tree\", \"tree graph\"]\n",
    "scores = get_scores(queries, text_probes=[\"a photo of a real tree\", \"a drawing of a tree diagram\"])\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5037ccc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  7],\n",
       "       [ 0, 49]], dtype=int64)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870195c7",
   "metadata": {},
   "source": [
    "Probes tried: \n",
    "\n",
    "    1. [\"a photo of a tree\", \"a photo of a tree graph\"] \n",
    "        [[37, 13],\n",
    "       [ 0, 49]]\n",
    "       \n",
    "    2. [\"a photo of a natural tree\", \"a photo of a tree graph\"]  \n",
    "        [(40, 10), \n",
    "        (0, 49)]\n",
    "        \n",
    "    3. [\"a photo of a planted tree\", \"a photo of a tree graph\"]\n",
    "        [(35, 15), \n",
    "        (0, 49)]\n",
    "        \n",
    "    4.  [\"a photo of a natural tree\", \"a photo of a tree diagram\"] \n",
    "        [[42,  8],\n",
    "        [ 0, 49]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87562a58",
   "metadata": {},
   "source": [
    "## Basket (wicker vs basketball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3fb1fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/wicker_basket\n",
      "./images_google_search/basketball_basket\n"
     ]
    }
   ],
   "source": [
    "queries = [\"wicker basket\", \"basketball basket\"]\n",
    "scores = get_scores(queries, text_probes=[\"wooden basket\", \"basketball basket\"])\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9fc5fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0],\n",
       "       [ 0, 51]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "029fb7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/finger_nail\n",
      "./images_google_search/iron_nail\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[49,  0],\n",
       "       [ 0, 51]], dtype=int64)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"finger nail\", \"iron nail\"]\n",
    "scores = get_scores(queries, text_probes=[\"a photo of a human nail\", \"a photo of a tool nail\"])\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "96d66828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  0],\n",
       "       [ 3, 48]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d43d578e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/iron_nail\n"
     ]
    }
   ],
   "source": [
    "images = dict([(q, load_images(image_dir+'/'+q)) for q in [\"iron nail\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3cf39c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/file_tool\n",
      "./images_google_search/file_stationery\n"
     ]
    }
   ],
   "source": [
    "queries = [\"file tool\", \"file stationery\"]\n",
    "scores = get_scores(queries)\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89a93213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  0],\n",
       "       [ 0, 51]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3885f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/man\n",
      "./images_google_search/cartoon_man\n"
     ]
    }
   ],
   "source": [
    "queries = [\"man\", \"cartoon man\"]\n",
    "scores = get_scores(queries, text_probes=[\"a photo of a real man\", \"a picture of a cartoon man\"])\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cee49959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41,  9],\n",
       "       [ 0, 49]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "813a8fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/fat_man\n",
      "./images_google_search/thin_man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[44,  6],\n",
       "       [ 3, 47]], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"fat man\", \"thin man\"]\n",
    "scores = get_scores(queries, text_probes=None)\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7f578498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/tall_man\n",
      "./images_google_search/short_man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[34, 16],\n",
       "       [26, 23]], dtype=int64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"tall man\", \"short man\"]\n",
    "scores = get_scores(queries, text_probes=None)\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "86de3252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/fat_cow\n",
      "./images_google_search/thin_cow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[23, 27],\n",
       "       [ 1, 49]], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"fat cow\", \"thin cow\"]\n",
    "scores = get_scores(queries, text_probes=None)\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "76d7500d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/tall_cow\n",
      "./images_google_search/short_cow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30, 19],\n",
       "       [ 4, 46]], dtype=int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"tall cow\", \"short cow\"]\n",
    "scores = get_scores(queries, text_probes=None)\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1bd4c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/sitting_man\n",
      "./images_google_search/standing_man\n",
      "./images_google_search/running_man\n",
      "./images_google_search/walking_man\n",
      "./images_google_search/smiling_man\n",
      "./images_google_search/frowning_man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[49,  0,  0,  0,  1,  0],\n",
       "       [ 0, 48,  0,  1,  0,  0],\n",
       "       [ 0,  0, 48,  0,  1,  0],\n",
       "       [ 0, 12,  6, 33,  0,  0],\n",
       "       [ 1,  3,  0,  0, 46,  0],\n",
       "       [ 1,  0,  0,  0,  1, 47]], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"sitting man\", \"standing man\", \"running man\", \"walking man\", \"smiling man\", \"frowning man\"]\n",
    "scores = get_scores(queries, text_probes=None)\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2ad901a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/green_cat\n",
      "./images_google_search/green_frog\n",
      "./images_google_search/yellow_cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[48,  0,  2],\n",
       "       [ 0, 50,  0],\n",
       "       [ 1,  0, 50]], dtype=int64)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"green cat\", \"green frog\", \"yellow cat\"]\n",
    "scores = get_scores(queries, text_probes=None)\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7b3f10a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/green_grass\n",
      "./images_google_search/red_grass\n",
      "./images_google_search/red_ball\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[52,  0,  0],\n",
       "       [ 4, 46,  0],\n",
       "       [ 0,  0, 49]], dtype=int64)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"green grass\", \"red grass\", \"red ball\"]\n",
    "scores = get_scores(queries, text_probes=[\"a photo of green grass\", \"a photo of red grass\", \"a photo of red ball\"])\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a6ecfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images_google_search/cat_on_grass_during_day\n",
      "./images_google_search/dog_on_grass_during_day\n",
      "./images_google_search/deer_on_grass_during_day\n",
      "./images_google_search/cow_on_grass_during_day\n",
      "./images_google_search/pig_on_grass_during_day\n"
     ]
    }
   ],
   "source": [
    "classes = [\"cat\",\"dog\", \"deer\", \"cow\", \"pig\"]\n",
    "queries = [c+\" on grass during day\" for c in classes]\n",
    "scores = get_scores(queries, text_probes=[\"a cartoon of a \"+c+\" on grass\" for c in classes])\n",
    "predictions = np.array([np.bincount([int(s.argmax()) for s in scores[q]], minlength=len(queries)) for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45cb6bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  0,  0,  0,  0],\n",
       "       [ 0, 91,  0,  1,  1],\n",
       "       [ 0,  1, 43,  0,  0],\n",
       "       [ 0,  0,  1, 42,  1],\n",
       "       [ 0,  0,  0,  0, 48]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c7ce06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  0,  0,  0,  0],\n",
       "       [ 1, 91,  0,  1,  0],\n",
       "       [ 0,  1, 43,  0,  0],\n",
       "       [ 0,  1,  0, 43,  0],\n",
       "       [ 0,  0,  0,  0, 48]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4daacd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  2,  0,  0,  7],\n",
       "       [ 1, 72,  1,  7, 12],\n",
       "       [ 1,  0, 37,  4,  2],\n",
       "       [ 0,  1,  1, 38,  4],\n",
       "       [ 0,  1,  1,  7, 39]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
